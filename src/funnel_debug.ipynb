{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 18:23:45.751385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-22 18:23:45.751454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-22 18:23:45.751460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-09-22 18:23:48.653728: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:433] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "import jax\n",
    "from jax.flatten_util import ravel_pytree\n",
    "import argparse\n",
    "import boundingmachine as bm\n",
    "import mcdboundingmachine as mcdbm\n",
    "import opt\n",
    "from model_handler import load_model\n",
    "import pickle\n",
    "import ml_collections.config_flags\n",
    "import wandb\n",
    "from absl import app, flags\n",
    "from utils import flatten_nested_dict, update_config_dict, setup_training, make_grid, W2_distance\n",
    "from jax import scipy as jscipy\n",
    "from configs.base import LR_DICT, get_config\n",
    "\n",
    "import os\n",
    "import ot\n",
    "# Set XLA_PYTHON_CLIENT_PREALLOCATE flag\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# tf.config.experimental.set_visible_devices([], \"GPU\")\n",
    "# python main.py --config.model funnel --config.boundmode MCD_ULA\n",
    "\n",
    "# Boundmodes\n",
    "# \t- ULA uses MCD_ULA\n",
    "# \t- MCD uses MCD_ULA_sn\n",
    "#\t- UHA uses UHA\n",
    "# \t- LDVI uses MCD_U_a-lp-sn\n",
    "#   - CAIS uses MCD_CAIS_sn\n",
    "#   - CAIS_UHA uses MCD_CAIS_UHA_sn\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "config.model = \"funnel\"\n",
    "config.boundmode = \"MCD_ULA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 5\n",
      "alpha: 0.05\n",
      "boundmode: MCD_ULA\n",
      "funnel_clipy: 11\n",
      "funnel_d: 10\n",
      "funnel_sig: 3\n",
      "hidden_dim: 1000\n",
      "id: -1\n",
      "im_size: 14\n",
      "init_eps: 1.0e-05\n",
      "init_eta: 0.0\n",
      "iters: 150000\n",
      "lfsteps: 1\n",
      "lr: 0.0001\n",
      "mfvi_iters: 15000\n",
      "mfvi_lr: 0.0001\n",
      "model: funnel\n",
      "n_bits: 3\n",
      "n_input_dist_seeds: 30\n",
      "n_samples: 500\n",
      "nbridges: 8\n",
      "pretrain_mfvi: true\n",
      "run_cluster: 0\n",
      "seed: 1\n",
      "train_eps: true\n",
      "train_vi: true\n",
      "wandb:\n",
      "  code_dir: /home/sp2058/CAIS/src\n",
      "  entity: shreyaspadhy\n",
      "  log: true\n",
      "  log_artifact: true\n",
      "  name: ''\n",
      "  project: cais\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshreyaspadhy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sp2058/CAIS/src/wandb/run-20230922_172331-ibielebv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/shreyaspadhy/CAIS-src/runs/ibielebv\" target=\"_blank\">gallant-wildflower-6</a></strong> to <a href=\"https://wandb.ai/shreyaspadhy/CAIS-src\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('eta', 'gamma', 'mgridref_y', 'eps', 'vd')\n",
      "No score network needed by the method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 58.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training, got ELBO -2.22.\n",
      "Done training, got ln Z -0.84.\n"
     ]
    }
   ],
   "source": [
    "print(config)\n",
    "\n",
    "config.pretrain_mfvi = False\n",
    "config.iters = 1000\n",
    "\n",
    "\n",
    "wandb.init()\n",
    "iters_base=config.iters\n",
    "log_prob_model, dim, sample_from_target_fn = load_model(config.model, config)\n",
    "rng_key_gen = jax.random.PRNGKey(config.seed)\n",
    "\n",
    "train_rng_key_gen, eval_rng_key_gen = jax.random.split(rng_key_gen)\n",
    "\n",
    "# Train initial variational distribution to maximize the ELBO\n",
    "trainable=('vd',)\n",
    "params_flat, unflatten, params_fixed = bm.initialize(dim=dim, nbridges=0, trainable=trainable)\n",
    "\n",
    "\n",
    "grad_and_loss = jax.jit(jax.grad(bm.compute_bound, 1, has_aux = True), static_argnums = (2, 3, 4))\n",
    "if not config.pretrain_mfvi:\n",
    "    mfvi_iters = 1\n",
    "    vdparams_init = unflatten(params_flat)[0]['vd']\n",
    "else:\n",
    "    mfvi_iters = config.mfvi_iters\n",
    "    losses, diverged, params_flat, tracker = opt.run(\n",
    "        config, config.mfvi_lr, mfvi_iters, params_flat, unflatten, params_fixed,\n",
    "        log_prob_model, grad_and_loss, trainable, train_rng_key_gen, log_prefix='pretrain')\n",
    "    vdparams_init = unflatten(params_flat)[0]['vd']\n",
    "\n",
    "    elbo_init = -np.mean(np.array(losses[-500:]))\n",
    "    print('Done training initial parameters, got ELBO %.2f.' % elbo_init)\n",
    "    wandb.log({'elbo_init': onp.array(elbo_init)})\n",
    "\n",
    "if config.boundmode == 'UHA':\n",
    "    trainable = ('eta', 'mgridref_y')\n",
    "    if config.train_eps:\n",
    "        trainable = trainable + ('eps',)\n",
    "    if config.train_vi:\n",
    "        trainable = trainable + ('vd',)\n",
    "    params_flat, unflatten, params_fixed = bm.initialize(dim=dim, nbridges=config.nbridges, eta=config.init_eta, eps = config.init_eps,\n",
    "        lfsteps=config.lfsteps, vdparams=vdparams_init, trainable=trainable)\n",
    "    grad_and_loss = jax.jit(jax.grad(bm.compute_bound, 1, has_aux = True), static_argnums = (2, 3, 4))\n",
    "\n",
    "    loss_fn = jax.jit(bm.compute_bound, static_argnums = (2, 3, 4))\n",
    "\n",
    "elif 'MCD' in config.boundmode:\n",
    "    trainable = ('eta', 'gamma', 'mgridref_y')\n",
    "    if config.train_eps:\n",
    "        trainable = trainable + ('eps',)\n",
    "    if config.train_vi:\n",
    "        trainable = trainable + ('vd',)\n",
    "    \n",
    "    print(trainable)\n",
    "    params_flat, unflatten, params_fixed = mcdbm.initialize(dim=dim, nbridges=config.nbridges, vdparams=vdparams_init, eta=config.init_eta, eps = config.init_eps,\n",
    "        trainable=trainable, mode=config.boundmode)\n",
    "    grad_and_loss = jax.jit(jax.grad(mcdbm.compute_bound, 1, has_aux = True), static_argnums = (2, 3, 4))\n",
    "\n",
    "    loss_fn = jax.jit(mcdbm.compute_bound, static_argnums = (2, 3, 4))\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError('Mode %s not implemented.' % config.boundmode)\n",
    "\n",
    "# Average over 30 seeds, 500 samples each after training is done.\n",
    "n_samples = config.n_samples\n",
    "n_input_dist_seeds = config.n_input_dist_seeds\n",
    "\n",
    "target_samples = sample_from_target_fn(jax.random.PRNGKey(1), n_samples * n_input_dist_seeds)\n",
    "\n",
    "losses, diverged, params_flat, tracker = opt.run(config, config.lr, config.iters, params_flat, unflatten, params_fixed, log_prob_model, grad_and_loss,\n",
    "    trainable, train_rng_key_gen, log_prefix='train', target_samples=target_samples)\n",
    "\n",
    "\n",
    "eval_losses, samples = opt.sample(\n",
    "    config, n_samples, n_input_dist_seeds, params_flat, unflatten, params_fixed, log_prob_model, loss_fn,\n",
    "    eval_rng_key_gen, log_prefix='eval')\n",
    "\n",
    "# (n_input_dist_seeds, n_samples)\n",
    "eval_losses = np.array(eval_losses)\n",
    "\n",
    "# Calculate mean and std of ELBOs over 30 seeds\n",
    "final_elbos = -np.mean(eval_losses, axis=1)\n",
    "final_elbo = np.mean(final_elbos)\n",
    "final_elbo_std = np.std(final_elbos)\n",
    "\n",
    "# Calculate mean and std of log Zs over 30 seeds\n",
    "ln_numsamp = np.log(n_samples)\n",
    "\n",
    "final_ln_Zs = jscipy.special.logsumexp(-np.array(eval_losses), axis=1)  - ln_numsamp\n",
    "\n",
    "final_ln_Z = np.mean(final_ln_Zs)\n",
    "final_ln_Z_std = np.std(final_ln_Zs)\n",
    "\n",
    "print('Done training, got ELBO %.2f.' % final_elbo)\n",
    "print('Done training, got ln Z %.2f.' % final_ln_Z)\n",
    "\n",
    "wandb.log({\n",
    "    'elbo_final': onp.array(final_elbo),\n",
    "    'final_ln_Z': onp.array(final_ln_Z),\n",
    "    'elbo_final_std': onp.array(final_elbo_std),\n",
    "    'final_ln_Z_std': onp.array(final_ln_Z_std)\n",
    "    })\n",
    "\n",
    "# Plot samples\n",
    "if config.model in [\"nice\", \"funnel\"]:\n",
    "    other_target_samples = sample_from_target_fn(jax.random.PRNGKey(2), samples.shape[0])\n",
    "\n",
    "    w2_dists, self_w2_dists = [], []\n",
    "    for i in range(n_input_dist_seeds):\n",
    "        \n",
    "        samples_i = samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "        target_samples_i = target_samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "        other_target_samples_i = other_target_samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "        w2_dists.append(W2_distance(samples_i, target_samples_i))\n",
    "        self_w2_dists.append(W2_distance(target_samples_i, other_target_samples_i))\n",
    "\n",
    "    if config.model == \"nice\":\n",
    "        make_grid(samples, config.im_size, n=64, wandb_prefix=\"images/sample\")\n",
    "    \n",
    "    wandb.log({\"w2_dist\": onp.mean(onp.array(w2_dists)),\n",
    "                \"w2_dist_std\": onp.std(onp.array(w2_dists)),\n",
    "                \"self_w2_dist\": onp.mean(onp.array(self_w2_dists)),\t\n",
    "                \"self_w2_dist_std\": onp.std(onp.array(self_w2_dists))})\n",
    "\n",
    "params_train, params_notrain = unflatten(params_flat)\n",
    "params = {**params_train, **params_notrain}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/sp2058/CAIS/src/funnel_debug.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcl/home/sp2058/CAIS/src/funnel_debug.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcl/home/sp2058/CAIS/src/funnel_debug.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m sinkhorn_divergence\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcl/home/sp2058/CAIS/src/funnel_debug.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msinkhorn\u001b[39;00m \u001b[39mimport\u001b[39;00m sinkhorn\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcl/home/sp2058/CAIS/src/funnel_debug.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(other_target_samples[:, \u001b[39m0\u001b[39m], other_target_samples[:, \u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcl/home/sp2058/CAIS/src/funnel_debug.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(samples[:, \u001b[39m0\u001b[39m],  samples[:, \u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/CAIS/src/sinkhorn.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Union\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpykeops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorch\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mkeops\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ldvi/lib/python3.10/site-packages/pykeops/torch/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m config \u001b[39mas\u001b[39;00m pykeopsconfig\n\u001b[1;32m      4\u001b[0m \u001b[39m##########################################################\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Check Pytorch install\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[39m# is the proper torch version  installed ?\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "other_target_samples = sample_from_target_fn(jax.random.PRNGKey(2), samples.shape[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import sinkhorn_divergence\n",
    "from sinkhorn import sinkhorn\n",
    "\n",
    "plt.plot(other_target_samples[:, 0], other_target_samples[:, 1], 'o')\n",
    "\n",
    "plt.plot(samples[:, 0],  samples[:, 1], 'o')\n",
    "\n",
    "plt.plot(target_samples[:, 0], target_samples[:, 1], 'o')\n",
    "plt.plot()\n",
    "\n",
    "w2_dists, self_w2_dists = [], []\n",
    "\n",
    "# fig, ax = plt.subplots(3, 3, figsize=(9, ,9))\n",
    "for i in range(9):\n",
    "    \n",
    "    samples_i = samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "    target_samples_i = target_samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "    other_target_samples_i = other_target_samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "    print(samples_i.shape, target_samples_i.shape, other_target_samples_i.shape)\n",
    "    w2_dists.append(sinkhorn(samples_i, target_samples_i))\n",
    "    self_w2_dists.append(sinkhorn_divergence(target_samples_i, other_target_samples_i))\n",
    "    # row, col = \n",
    "    plt.plot(other_target_samples_i[:, 0], other_target_samples_i[:, 1], 'o', label='other targets', alpha=0.5)\n",
    "    plt.plot(target_samples_i[:, 0], target_samples_i[:, 1], 'o', label='targets', alpha=0.5)\n",
    "    plt.plot(samples_i[:, 0],  samples_i[:, 1], 'x', label='samples', alpha=0.5)\n",
    "    plt.title(f'w2 dist : {w2_dists[-1]}, seld w2 dist : {self_w2_dists[-1]}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "w2_dists, self_w2_dists = np.array(w2_dists), np.array(self_w2_dists)\n",
    "\n",
    "print(w2_dists, self_w2_dists)\n",
    "print(f'self w2 dist: {np.mean(self_w2_dists)},std: {np.std(self_w2_dists)}')\n",
    "print(f'w2 dist: {np.mean(w2_dists)},std: {np.std(w2_dists)}')\n",
    "# w2_dists, self_w2_dists = [], []\n",
    "# for i in range(n_input_dist_seeds):\n",
    "    \n",
    "#     samples_i = samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "#     target_samples_i = target_samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "#     other_target_samples_i = other_target_samples[i * n_samples : (i + 1) * n_samples, ...]\n",
    "#     w2_dists.append(W2_distance(samples_i, target_samples_i))\n",
    "#     self_w2_dists.append(W2_distance(target_samples_i, other_target_samples_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldvi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
